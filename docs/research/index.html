<!DOCTYPE html>
<html lang="en-US">

<head>
  <meta http-equiv="X-Clacks-Overhead" content="GNU Terry Pratchett" />
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
<link rel="shortcut icon" href="https://abigailstone.github.io/images/favicon.png" />
<title>Research | Abigail Stone</title>
<meta name="title" content="Research" />
<meta name="description" content="Research Broadly, my research interests focus around new imaging technologies and computer vision algorithms that advance our understanding of the world around us: most importantly, computer vision technologies that help us create a more equitable society and help us to be better stewards of our planet.
Most recently, I&rsquo;ve been working on depth perception problems from a few different angles (both literally and figuratively), as well as deep learning models for hyperspectral imagery." />
<meta name="keywords" content="" />


<meta property="og:title" content="Research" />
<meta property="og:description" content="Research Broadly, my research interests focus around new imaging technologies and computer vision algorithms that advance our understanding of the world around us: most importantly, computer vision technologies that help us create a more equitable society and help us to be better stewards of our planet.
Most recently, I&rsquo;ve been working on depth perception problems from a few different angles (both literally and figuratively), as well as deep learning models for hyperspectral imagery." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://abigailstone.github.io/research/" /><meta property="article:section" content="" />

<meta property="og:site_name" content="Abigail Stone" />




<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Research"/>
<meta name="twitter:description" content="Research Broadly, my research interests focus around new imaging technologies and computer vision algorithms that advance our understanding of the world around us: most importantly, computer vision technologies that help us create a more equitable society and help us to be better stewards of our planet.
Most recently, I&rsquo;ve been working on depth perception problems from a few different angles (both literally and figuratively), as well as deep learning models for hyperspectral imagery."/>



<meta itemprop="name" content="Research">
<meta itemprop="description" content="Research Broadly, my research interests focus around new imaging technologies and computer vision algorithms that advance our understanding of the world around us: most importantly, computer vision technologies that help us create a more equitable society and help us to be better stewards of our planet.
Most recently, I&rsquo;ve been working on depth perception problems from a few different angles (both literally and figuratively), as well as deep learning models for hyperspectral imagery.">

<meta itemprop="wordCount" content="207">
<meta itemprop="keywords" content="" />
<meta name="referrer" content="no-referrer-when-downgrade" />

  <style>
  body {
    font-family: Verdana, sans-serif;
    margin: auto;
    padding: 20px;
    max-width: 720px;
    text-align: left;
    background-color: #fff;
    word-wrap: break-word;
    overflow-wrap: break-word;
    line-height: 1.5;
    color: #444;
  }

  h1,
  h2,
  h3,
  h4,
  h5,
  h6,
  strong,
  b {
    color: #222;
  }

  a {
    color: #3273dc;
     
  }

  .title {
    text-decoration: none;
    border: 0;
  }

  .title span {
    font-weight: 400;
  }

  nav a {
    margin-right: 10px;
  }

  textarea {
    width: 100%;
    font-size: 16px;
  }

  input {
    font-size: 16px;
  }

  content {
    line-height: 1.6;
  }

  table {
    width: 100%;
  }

  img {
    max-width: 100%;
  }

  code {
    padding: 2px 5px;
    background-color: #f2f2f2;
  }

  pre code {
    color: #222;
    display: block;
    padding: 20px;
    white-space: pre-wrap;
    font-size: 14px;
    overflow-x: auto;
  }

  div.highlight pre {
    background-color: initial;
    color: initial;
  }

  div.highlight code {
    background-color: unset;
    color: unset;
  }

  blockquote {
    border-left: 1px solid #999;
    color: #222;
    padding-left: 20px;
    font-style: italic;
  }

  footer {
    padding: 25px;
    text-align: center;
  }

  .helptext {
    color: #777;
    font-size: small;
  }

  .errorlist {
    color: #eba613;
    font-size: small;
  }

   
  ul.blog-posts {
    list-style-type: none;
    padding: unset;
  }

  ul.blog-posts li {
    display: flex;
  }

  ul.blog-posts li span {
    flex: 0 0 130px;
  }

  ul.blog-posts li a:visited {
    color: #8b6fcb;
  }

  @media (prefers-color-scheme: dark) {
    body {
      background-color: #333;
      color: #ddd;
    }

    h1,
    h2,
    h3,
    h4,
    h5,
    h6,
    strong,
    b {
      color: #eee;
    }

    a {
      color: #8cc2dd;
    }

    code {
      background-color: #777;
    }

    pre code {
      color: #ddd;
    }

    blockquote {
      color: #ccc;
    }

    textarea,
    input {
      background-color: #252525;
      color: #ddd;
    }

    .helptext {
      color: #aaa;
    }
  }

</style>

</head>

<body>
  <header><a href="/" class="title">
  <h2>Abigail Stone</h2>
</a>
<nav><a href="/">Home</a>

<a href="/research/">Research</a>

<a href="/projects/">Projects</a>


</nav>
</header>
  <main>

<content>
  <h1 id="research">Research</h1>
<p>Broadly, my research interests focus around new imaging technologies and computer vision algorithms that advance our understanding of the world around us: most importantly, computer vision technologies that help us create a more equitable society and help us to be better stewards of our planet.</p>
<p>Most recently, I&rsquo;ve been working on depth perception problems from a few different angles (both literally and figuratively), as well as deep learning models for hyperspectral imagery.</p>
<h3 id="publications">Publications</h3>
<p><a href="https://www.spiedigitallibrary.org/conference-proceedings-of-spie/13033/130330A/Towards-phenological-development-quantification-in-Brassica-plants-via-multispectral-imaging/10.1117/12.3014027.short">Towards phenological development quantification in <em>Brassica</em> plants via multispectral imaging and deep learning</a><br>
<strong>A. Stone</strong>, S. Rajeev, S.P. Rao, K. Panetta, S. Agaian<br>
SPIE Multimodal Image Exploitation and Learning 2024 (SPIE DCS 2024)</p>
<p><a href="https://www.spiedigitallibrary.org/conference-proceedings-of-spie/12526/125260N/Gaze-depth-estimation-for-eye-tracking-systems/10.1117/12.2664140.short#_=_">Gaze depth estimation for eye-tracking systems</a><br>
<strong>A. Stone</strong>, S. Rajeev, S.P. Rao, K. Panetta, S. Agaian, A. Gardony, J. Nordlund, R. Skantar <br>
SPIE Multimodal Image Exploitation and Learning 2023 (SPIE DCS 2023)</p>
<p><a href="https://ieeexplore.ieee.org/abstract/document/10024982/">A comprehensive 2D + 3D dataset for benchmarking hyperspectral imaging systems </a><br>
<strong>A. Stone</strong>, S. P. Rao, S. Rajeev, K. Panetta, and S. Agaian <br>
IEEE International Symposium on Technologies for Homeland Security (IEEE HST 2022, virtual presentation)</p>
<p><a href="https://www.spiedigitallibrary.org/conference-proceedings-of-spie/12100/121000N/Gaze-FTNet--a-feature-transverse-architecture-for-predicting-gaze/10.1117/12.2618989.short?SSO=1">Gaze-FTNet: a feature transverse architecture for predicting gaze attention</a> <br>
S. Rajeev, S. K. KM, <strong>A. Stone</strong>, K. Panetta, and S. S. Agaian<br>
SPIE Multimodal Image Exploitation and Learning 2022 (SPIE DCS 2022)</p>

</content>
<p>
  
</p>

  </main>
  <footer>Made with <a href="https://github.com/janraasch/hugo-bearblog/">Hugo ʕ•ᴥ•ʔ Bear</a><script data-goatcounter="https://abigailstone.goatcounter.com/count" async src="//gc.zgo.at/count.js"></script></footer>

    
</body>

</html>
